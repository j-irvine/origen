{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental Sampling Pipeline\n",
    "\n",
    "This notebook demonstrates the complete pipeline from sampling model generations and creating matched random mutants for experimental validation:\n",
    "1. Loading model generations and BLAST results (computed via respective scripts)\n",
    "2. Computing sequence similarities\n",
    "3. Sampling sequences based on similarity brackets\n",
    "4. Generating matched random mutants\n",
    "\n",
    "## Inputs\n",
    "Before using this notebook, run `scripts/generate_sequences.py` to generate sequences, and then `scripts/blast_script.sh` to blast those sequences against the training data. The resulting data will be used in this notebook.\n",
    "\n",
    "## Setup\n",
    "Install required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install biopython pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "\n",
    "from origen.alignment import compute_sequence_similarity\n",
    "from origen.random_mutants import generate_matched_random_mutant\n",
    "from origen.tokenizers import extract_oriv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Preprocess Data\n",
    "\n",
    "Load generated sequences and BLAST results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset = load_dataset('jirvine/origen-replicons-doric-and-plsdb')[\"train\"]\n",
    "\n",
    "# Create mapping from sequence IDs to sequences\n",
    "training_orivs = train_dataset['oriv_sequence']\n",
    "training_orivs_idx = {}\n",
    "for i, oriv in enumerate(training_orivs):\n",
    "   training_orivs_idx['seq' + str(i)] = oriv # zero-indexed\n",
    "\n",
    "# Load generated sequences\n",
    "with open('path/to/generated_seqs.txt', 'r') as f:\n",
    "    generations = f.readlines()\n",
    "\n",
    "# Process generated sequences\n",
    "generated_orivs_idx = {}\n",
    "for i, generation in enumerate(generations):\n",
    "    generated_oriv = extract_oriv(generation)\n",
    "    generated_orivs_idx[f'seq{i+1}'] = generated_oriv  # 1-indexed\n",
    "\n",
    "# Load BLAST results\n",
    "blast_hits = pd.read_csv('path/to/blast_hits.tsv', sep='\\t')\n",
    "\n",
    "# Add sequences and lengths to blast hits\n",
    "blast_hits['query_seq'] = blast_hits['query_id'].map(generated_orivs_idx)\n",
    "blast_hits['subject_seq'] = blast_hits['subject_id'].map(training_orivs_idx)\n",
    "blast_hits['query_length'] = blast_hits['query_seq'].str.len()\n",
    "blast_hits['subject_length'] = blast_hits['subject_seq'].str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compute Sequence Similarities\n",
    "\n",
    "Calculate similarity scores for all BLAST hits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate similarities using needle alignment\n",
    "blast_hits['needle'] = blast_hits.apply(\n",
    "    lambda row: compute_sequence_similarity(row['query_seq'], row['subject_seq']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Filter by length difference, to avoid low similarity due simply to length differences\n",
    "LENGTH_DIFF_THRESHOLD = 10\n",
    "blast_hits_filtered = blast_hits[\n",
    "    (blast_hits['query_length'] >= blast_hits['subject_length'] - LENGTH_DIFF_THRESHOLD) &\n",
    "    (blast_hits['query_length'] <= blast_hits['subject_length'] + LENGTH_DIFF_THRESHOLD)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sample by Similarity Brackets\n",
    "\n",
    "Group sequences into similarity brackets and sample representatives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define similarity brackets\n",
    "brackets = [\n",
    "    (99, 100), (98, 99), (97, 98), (96, 97), (95, 96), (94, 95), (93, 94),\n",
    "    (92, 93), (91, 92), (90, 91), (89, 90), (88, 89), (87, 88), (86, 87),\n",
    "    (85, 86), (84, 85), (83, 84), (82, 83), (81, 82), (80, 81)\n",
    "]\n",
    "\n",
    "# Sample sequences from each bracket\n",
    "sampled_sequences = []\n",
    "for min_needle, max_needle in brackets:\n",
    "    bracket_df = blast_hits_filtered[\n",
    "        (100 * blast_hits_filtered['needle'] >= min_needle) & \n",
    "        (100 * blast_hits_filtered['needle'] < max_needle)\n",
    "    ]\n",
    "    if not bracket_df.empty:\n",
    "        sample = bracket_df.sample(n=1, random_state=42)\n",
    "        sampled_sequences.append({\n",
    "            'bracket': f'{min_needle}-{max_needle}',\n",
    "            'query_seq': sample['query_seq'].iloc[0],\n",
    "            'subject_seq': sample['subject_seq'].iloc[0],\n",
    "            'similarity': sample['needle'].iloc[0]\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate Matched Random Mutants\n",
    "\n",
    "For each sampled sequence pair, generate a matched random mutant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate matched random mutants\n",
    "for seq in sampled_sequences:\n",
    "    random_mutant = generate_matched_random_mutant(\n",
    "        seq['query_seq'],\n",
    "        seq['subject_seq']\n",
    "    )\n",
    "    seq['random_mutant'] = random_mutant\n",
    "    seq['random_mutant_similarity'] = compute_sequence_similarity(\n",
    "        random_mutant,\n",
    "        seq['subject_seq']\n",
    "    )\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(sampled_sequences)\n",
    "print(\"Sampling and random mutant generation complete!\")\n",
    "results_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
